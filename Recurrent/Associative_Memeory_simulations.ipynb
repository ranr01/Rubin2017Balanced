{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab nbagg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for measuring basins of attraction and ouput noise robustness of associative memory networks\n",
    "\n",
    "This code uses Ipython-parallel to train and test the recurrent networks in parallel.\n",
    "Can be run locally or on a cluster.\n",
    "\n",
    "## Ipython parallel setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here it is assumed the the Ipython cluster and engiens are up and running\n",
    "import ipyparallel as ipp\n",
    "ipp_client = ipp.Client()\n",
    "dview = ipp_client.direct_view()\n",
    "lbview = ipp_client.load_balanced_view()\n",
    "print('Using {} engines'.format(len(lbview)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure engines are working from the same directory as our local kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "dview['wd'] = cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import os\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local and remote defs for learning and network simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# functions to find max kappa_in and max kappa_out weights\n",
    "from max_kappa import sign_constrained_perceptron_max_kappa_out,\\\n",
    "                      sign_constrained_perceptron_max_kappa_in\n",
    "\n",
    "# functions to train and test the recurrent networks\n",
    "import associative_memory\n",
    "# functions from associative_memory module should be available globally\n",
    "from associative_memory import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import ipywidgets\n",
    "\n",
    "# visualization of parallel jobs progress (optional)\n",
    "@asyncio.coroutine    \n",
    "def progress_bar(a):\n",
    "    w=ipywidgets.FloatProgress()\n",
    "    display(w)\n",
    "    while not a.done():\n",
    "        w.value = (100 * a.progress) / len(a.submitted)\n",
    "        yield from asyncio.sleep(0.5)\n",
    "    w.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Here we train networks that implements a given set of random memory states as fixed points of the network dynamics. For each memory patterns sets we find the maximal $\\kappa_\\mathrm{in}$ and maximal $\\kappa_\\mathrm{out}$ weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "N=2000 # number of neurons in network\n",
    "alpha=0.25 # network load P = alpha*N\n",
    "f_ex=0.3 # activity level of excitatory neurons (in memory states)\n",
    "f_inh=0.15 # activity level of inhibitory neurons (in memory states)\n",
    "g_ex=0.8 # fraction of excitatory neurons\n",
    "n_network=10 # number of networks to train (for averaging over several sets of patterns)\n",
    "\n",
    "#list of learned networks\n",
    "networks=[]\n",
    "\n",
    "#progress visualization\n",
    "w=ipywidgets.FloatProgress()\n",
    "display(w)\n",
    "\n",
    "for n in range(len(networks),n_network):\n",
    "    w.value = 100. * n / n_network\n",
    "    \n",
    "    # Create a set of memories to encode in the network\n",
    "    X,g = random_patterns_network(N,f_ex,f_inh,g_ex,alpha)\n",
    "\n",
    "    # Send patterns and neurons type to engiens \n",
    "    # (For many engines using dview.push can be inefficient, alternative approaches are to\n",
    "    # save to disk and load from each engine, or use more efficient comunications (e.g. mpi broadcast)) \n",
    "    a=dview.push({'X':X,'g':g},block=True)\n",
    "    \n",
    "    # learn max kappa_in weights\n",
    "    w_kappa_in,c,c1=learn_network(\\\n",
    "            sign_constrained_perceptron_max_kappa_in,N,lbview)\n",
    "\n",
    "    print('Max kappa_in network: all_conerged={}, memories_are_fixed_points={}'.format(c,c1))\n",
    "\n",
    "    # learn max kappa_out weights\n",
    "    w_kappa_out,c,c1=learn_network(\\\n",
    "            sign_constrained_perceptron_max_kappa_out,N,lbview)\n",
    "\n",
    "    print('Max kappa_out network: all_conerged={}, memories_are_fixed_points={}'.format(c,c1))\n",
    "\n",
    "    # create learned network dictionary\n",
    "    networks.append(dict(f_ex=f_ex,f_inh=f_inh,X=X,g=g,w_kappa_in=w_kappa_in,w_kappa_out=w_kappa_out))\n",
    "    \n",
    "    # For large networks it might be a good idea to save the networks to disk at this point\n",
    "w.value = 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "For testing the networks we assume that the `networks` list is defined globally for each engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pushing networks to engiens.\n",
    "# again, for many engines using this can be inefficient. See previouse comment for alternative approches\n",
    "dview['networks'] = networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_sigma(sigma,n_rep,P_max,n_network,Jij_key,chunksize=10):\n",
    "    ''' \n",
    "    Test the robustness to output noise of magnitude sigma.\n",
    "    \n",
    "    # paramaters:\n",
    "    \n",
    "    * sigma - magnitude of output noise\n",
    "    * n_rep - number of times to test each pattern\n",
    "    * P_max - number of patterns to test from each network\n",
    "    * n_network - number of networks to test\n",
    "    * Jij_key - the name of the weights to use for testing (i.e. 'w_kappa_in' or 'w_kappa_out')\n",
    "    * chunksize - number of jobs to send in each task\n",
    "    \n",
    "    # returns\n",
    "    \n",
    "    returns an async result object (see usage below)\n",
    "    \n",
    "    '''\n",
    "    #function to run remotely (tests pattern mu from network net_ind)\n",
    "    # this function assumes `networks` are defined in global scope in each engine\n",
    "    f = lambda net_ind,mu:\\\n",
    "            test_stochastic_dynamics(sigma,\\\n",
    "                                     networks[net_ind][Jij_key],\\\n",
    "                                     networks[net_ind]['X'][:,mu:mu+1],\\\n",
    "                                     err_thr=0.1)    \n",
    "    #arguments of f\n",
    "    net_inds = np.hstack([ind*np.ones(n_rep*P_max,dtype=int) for ind in range(n_network)])\n",
    "    mu_inds =  np.hstack([(arange(P_max)*ones((n_rep,P_max),dtype=int)).T.flatten()\\\n",
    "                                for ind in range(n_network)])\n",
    "    \n",
    "    #remote map\n",
    "    async_map_result = lbview.map(f,net_inds,mu_inds,block=False,chunksize=chunksize)\n",
    "\n",
    "    return async_map_result\n",
    "\n",
    "#parameters\n",
    "sigma_vec_in = 10**arange(-3.,-1.3,0.04) # values of sigma to test for manx kappa_in solutions\n",
    "sigma_vec_out = 10**arange(-1.,1,0.04) # values of sigma to test for manx kappa_out solutions\n",
    "n_rep = 1 # repetitions per patterns\n",
    "P_max = 100 # patterns per netwokrs\n",
    "n_network = 10 # number of networks\n",
    "\n",
    "# submiting jobs\n",
    "amr_in = [test_sigma(s,n_rep,P_max,n_network,'w_kappa_in',chunksize=10) for s in sigma_vec_in]\n",
    "amr_out = [test_sigma(s,n_rep,P_max,n_network,'w_kappa_out',chunksize=10) for s in sigma_vec_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display progress bars for each task (bar is closed when task is complete) \n",
    "\n",
    "loop=asyncio.get_event_loop()\n",
    "tasks = [asyncio.Task(progress_bar(a)) for a in amr_in] +\\\n",
    "        [asyncio.Task(progress_bar(a)) for a in amr_out]\n",
    "_=loop.run_until_complete(asyncio.wait(tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculating stable pattarn probability\n",
    "p_conv_in=[]\n",
    "\n",
    "for a in amr_in:\n",
    "    e,t=zip(*a.get())\n",
    "    p_conv_in.append(np.mean(np.array(t)==500))\n",
    "    \n",
    "p_conv_out=[]\n",
    "for a in amr_out:\n",
    "    e,t=zip(*a.get())\n",
    "    p_conv_out.append(np.mean(np.array(t)==500))\n",
    "\n",
    "#plot results\n",
    "close()\n",
    "plot(sigma_vec_in,p_conv_in)\n",
    "plot(sigma_vec_out,p_conv_out)\n",
    "xscale('log')\n",
    "ylim(-0.1,1.1)\n",
    "grid(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basins of attraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_basins(p,n_rep,P_max,n_network,Jij_key,chunksize=10):\n",
    "    ''' \n",
    "    Test the convergence of patterns with initial distortion p.\n",
    "    \n",
    "    # paramaters:\n",
    "    \n",
    "    * p - magnitude of initial pattern distortion\n",
    "    * n_rep - number of times to test each pattern\n",
    "    * P_max - number of patterns to test from each network\n",
    "    * n_network - number of networks to test\n",
    "    * Jij_key - the name of the weights to use for testing (i.e. 'w_kappa_in' or 'w_kappa_out')\n",
    "    * chunksize - number of jobs to send in each task\n",
    "    \n",
    "    # returns\n",
    "    \n",
    "    returns an async result object (see usage below)\n",
    "    \n",
    "    '''\n",
    "    #function to run remotely (tests pattern mu from network net_ind)\n",
    "    f = lambda net_ind,mu:\\\n",
    "            test_basin(p,\\\n",
    "                       networks[net_ind][Jij_key],\\\n",
    "                       networks[net_ind]['g'],\\\n",
    "                       networks[net_ind]['f_ex'],\\\n",
    "                       networks[net_ind]['f_inh'],\\\n",
    "                       networks[net_ind]['X'][:,mu:mu+1],\\\n",
    "                       err_thr=0.15)    \n",
    "\n",
    "    #argumrnts of f\n",
    "    net_inds = np.hstack([ind*np.ones(n_rep*P_max,dtype=int) for ind in range(n_network)])\n",
    "    mu_inds =  np.hstack([(arange(P_max)*ones((n_rep,P_max),dtype=int)).T.flatten()\\\n",
    "                                for ind in range(n_network)])\n",
    "    \n",
    "    #remote map\n",
    "    async_map_result = lbview.map(f,net_inds,mu_inds,block=False,chunksize=chunksize)\n",
    "\n",
    "    return async_map_result\n",
    "\n",
    "#parameters\n",
    "p_vec = arange(0.02,0.30,0.01) # values of initial distortion to test\n",
    "n_rep = 10 # repetitions per patterns\n",
    "P_max = 10 # patterns per netwokrs\n",
    "n_network = 10 # number of networks\n",
    "\n",
    "# submiting jobs\n",
    "amr_in = [test_basins(p,n_rep,P_max,n_network,'w_kappa_in',chunksize=10) for p in p_vec]\n",
    "amr_out = [test_basins(p,n_rep,P_max,n_network,'w_kappa_out',chunksize=10) for p in p_vec]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display progress bars for each task (bar is closed when task is complete) \n",
    "\n",
    "loop=asyncio.get_event_loop()\n",
    "tasks = [asyncio.Task(progress_bar(a)) for a in amr_in] +\\\n",
    "        [asyncio.Task(progress_bar(a)) for a in amr_out]\n",
    "_=loop.run_until_complete(asyncio.wait(tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate convergence probability\n",
    "\n",
    "pp_conv_out=[]\n",
    "for a in amr_out:\n",
    "    e0,e=zip(*a.get())\n",
    "    pp_conv_out.append(np.mean(np.array(e)==0.0))\n",
    "\n",
    "pp_conv_in=[]\n",
    "for a in amr_in:\n",
    "    e0,e=zip(*a.get())\n",
    "    pp_conv_in.append(np.mean(np.array(e)==0.0))\n",
    "\n",
    "#plot resutls\n",
    "close()\n",
    "plot(p_vec,pp_conv_in)\n",
    "plot(p_vec,pp_conv_out)\n",
    "ylim(0,1.1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
