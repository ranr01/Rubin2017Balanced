{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for figures 4 and 4S  from \"Balanced Excitation and Inhibition are Required for High-Capacity, Noise-Robust Neuronal Selectivity\"\n",
    "\n",
    "## Ran Rubin, Larry Abbott and Haim Sompolinsky\n",
    "\n",
    "Code by Ran Rubin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab nbagg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced vs. Unbalanced Solutions With Spiking Neurons\n",
    "\n",
    "We whish to use weights learned for the perceptron and test their performance on a spiking neuron.\n",
    "\n",
    "We define the neuron's input-output as follows:\n",
    "* Convert static input $x_i$ to rate: $r_i=Ax_i$. We use $A=30\\mathrm{Hz}$ and  $\\bar{x}_\\mathrm{exc}=\\sigma_\\mathrm{exc}=1$.\n",
    "* Input spike trains are drawn randomly from poisson process with rate $r_i$ for duration $T=200\\mathrm{ms}$. \n",
    "* The neuronal dynamics are a standard LIF neuron with current based, exponentially decaying synaptic inputs. We use a membrane time constant of $\\tau_m=30\\mathrm{ms}$, and a synaptic time constant of $\\tau_s=10\\mathrm{ms}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Generate Perceptron Input and desired Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of excitatory input activities\n",
    "Pex = lambda size: np.random.exponential(size=size)\n",
    "\n",
    "#Distribution of inhibitory input activities\n",
    "class Pinh(object):\n",
    "    def __init__(self,A,k,dxbar):\n",
    "        self.A=A\n",
    "        self.k=k\n",
    "        self.dxbar=dxbar\n",
    "    def __call__(self,size):\n",
    "        return self.A*np.random.gamma(self.k,size=size)+self.dxbar\n",
    "\n",
    "\n",
    "def gen_random_patterns(N,f_out,g_ex,alpha,Pex,Pinh):\n",
    "    '''Generates input patterns and desired output.\n",
    "    Input parameters:\n",
    "    -----------------\n",
    "    N - number of inputs\n",
    "    f_out - propability of an input pattern to belong to the 'plus' catagory\n",
    "    g_ex - fraction of excitatory inputs\n",
    "    alpha - Number of patterns to create as a fraction of N\n",
    "    Pex - A callable object to create excitatory activity\n",
    "    Pinh - A callable object to create inhibitory activity\n",
    "    \n",
    "    Pex and Pinh be callable with signature P(size=(N,P))  \n",
    "    and return an N by P array of input activities.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X - an NxP array of input activity patterns\n",
    "    y - a P vector of desired labels (+-1) with an avg. number of +1 of P*f_out\n",
    "    P - the number of patterns created\n",
    "    g - an N vector of the input affarent type: \n",
    "        +1 for an excitatory input and -1 for an inhibitory input.    \n",
    "    '''\n",
    "    #This leads to phi=lambda=sqrt(k)\n",
    "    P=int(alpha*N)\n",
    "    N_ex=int(g_ex*N)\n",
    "    N_inh=N-N_ex\n",
    "    X_ex=Pex(size=(N_ex,P))\n",
    "    X_inh=Pinh(size=(N_inh,P))\n",
    "    X=np.vstack((X_ex,X_inh))\n",
    "    y=2.*((np.random.rand(P,1)<f_out).astype(np.float))-1.\n",
    "    g=np.ones((N,1))\n",
    "    g[N_ex:]=-1.\n",
    "    return X,y,P,g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Generate Perceptron Solutions\n",
    "\n",
    "We formulate the problem as a conic programing problem and use a standard solver (CVXOPT, http://cvxopt.org/) to find the solutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../QuadProg/')\n",
    "from max_kappa import sign_constrained_perceptron_max_kappa_out, \\\n",
    "                      sign_constrained_perceptron_max_kappa_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IpyParallel\n",
    "\n",
    "We use Ipython Parallel (https://github.com/ipython/ipyparallel) to parallelize the simulations on a cluster. \n",
    "However, the same code will run locally on a multi core computer just fine. One just need to set up the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "import ipyparallel as parallel\n",
    "\n",
    "ipyp_profile='default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Connecting a client to the cluster (which you should set up before)\n",
    "c = Client(profile=ipyp_profile)\n",
    "dview=c[:]\n",
    "lbview=c.load_balanced_view()\n",
    "print(len(lbview)) #number of connected engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd=os.getcwd()\n",
    "dview['cwd']=cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "\n",
    "# For LIF simulation I use my own C++ extension library that implements a\n",
    "# highly efficient event based simulation of the LIF neuron developed by Robert Gutig \n",
    "# and myself.\n",
    "# The library was written to implement learning in spiking neurons (See my previouse work) \n",
    "# and contains several dynamic and learning models. \n",
    "# However, here we only use it to simply generate spiking inputs from rate inputs and simulate the LIF dynamics\n",
    "import sys\n",
    "#sys.path.append('path to were the SpikingTempotron package resides')\n",
    "sys.path.append(cwd)\n",
    "\n",
    "import SpikingTempotron as ST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting different random seeds for each engine. \n",
    "#Note that using the same seed will not guaranty exactly the same results \n",
    "#since we do not expilicitly control which job will be sent to which engine  \n",
    "import time\n",
    "numpy_seed=23549264\n",
    "cpp_seed=98982967\n",
    "np.random.seed(numpy_seed)\n",
    "dview.scatter('numpy_seed',numpy_seed+arange(1,len(lbview)+1))\n",
    "dview.scatter('cpp_seed',cpp_seed+arange(1,len(lbview)+1))\n",
    "r1=dview.execute('np.random.seed(numpy_seed[0])')\n",
    "r2=dview.execute('ST.setRNGenSeed(int(cpp_seed[0]))') #this is the RNG inside the C++ extension library\n",
    "while not(r1.done() and r2.done()):\n",
    "    time.sleep(1)\n",
    "#A (True,True) output implies success\n",
    "(array(r1.status)=='ok').all(),(array(r2.status)=='ok').all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000 # Number of neurons\n",
    "g_ex=0.8 # Fraction of excitatory inputs\n",
    "f_out=0.1 # Fraction of 'plus' patterns\n",
    "#Parameters for inhibitory activity distribution\n",
    "k=2. \n",
    "dxbar=.0\n",
    "A_inh=sqrt(2.)\n",
    "\n",
    "alpha=1. # Load\n",
    "P=1000 # Number of patterns\n",
    "Gamma = 1.5 # Maximal norm of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending N and P to all engines\n",
    "dview['N']=N\n",
    "dview['P']=P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px \n",
    "#Neuron's parameters:\n",
    "#time in sec\n",
    "tau_m = 0.03\n",
    "tau_s = 0.01\n",
    "T = 0.2\n",
    "LIFtheta = 1.\n",
    "\n",
    "#PSP_Kernel (Double exponential kernel to be used inside the LIF neuron)\n",
    "K = ST.PSP_Kernel(tau_m,tau_s)\n",
    "K.T = T\n",
    "\n",
    "#Units of x:\n",
    "A = 30 #in Hz\n",
    "\n",
    "#noise parameters\n",
    "#Parameters for low noise conditions\n",
    "N_noise = 1\n",
    "sigma_noise_w = 0./sqrt(N_noise)\n",
    "\n",
    "#An LIF neuron that will test the max kappa_in solution \n",
    "tempo_in = ST.SpikingTempotron(N+N_noise,1.,0.,LIFtheta)\n",
    "tempo_in.K = K\n",
    "\n",
    "#An LIF neuron that will test the max kappa_out solution\n",
    "tempo_out = ST.SpikingTempotron(N+N_noise,1.,0.,LIFtheta)\n",
    "tempo_out.K = K\n",
    "\n",
    "#A funtion to set the weights of the LIF neurons\n",
    "def set_weights():\n",
    "    tempo_in.w = hstack([w_in,sigma_noise_w*random.randn(N_noise)])\n",
    "    tempo_out.w = hstack([w_out,sigma_noise_w*random.randn(N_noise)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to activate LIF neurons with input pattern $\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions are defined locally but will be sent to remote engines.\n",
    "#Thus they refer to global varaibles that are defined on remote engines.\n",
    "\n",
    "def activate_in(mu):\n",
    "    '''\n",
    "    Activate the max kappa_in LIF neuron with input pattern mu\n",
    "    Returns the number of output spikes.\n",
    "    '''\n",
    "    # Create Poisson Spike-trains from input pattern\n",
    "    spk_train = ST.CPPgeneratePoissonSpikeTrian(X[:,mu]*A,T,N,N_noise) \n",
    "    # Pre-calculate exponents of input spike times \n",
    "    spk_train.calcExponents(K)\n",
    "    #activates the max kappa_in LIF neuron with created spike train \n",
    "    tempo=tempo_in\n",
    "    tempo.setPattern(spk_train) \n",
    "    tempo.restart()\n",
    "    tempo.activate_no_teacher() #actual event base LIF simulation\n",
    "    return len(tempo.crossings()) # tempo.crossings() is an array with output spike times following the activation\n",
    "def activate_out(mu):\n",
    "    '''\n",
    "    Activate the max kappa_out LIF neuron with input pattern mu\n",
    "    Returns the number of output spikes.\n",
    "    '''\n",
    "    spk_train = ST.CPPgeneratePoissonSpikeTrian(X[:,mu]*A,T,N,N_noise)\n",
    "    spk_train.calcExponents(K)\n",
    "    tempo=tempo_out\n",
    "    tempo.setPattern(spk_train)\n",
    "    tempo.restart()\n",
    "    tempo.activate_no_teacher()\n",
    "    return len(tempo.crossings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to perform simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppress detailed output of optimization\n",
    "import cvxopt\n",
    "cvxopt.solvers.options['show_progress']=False\n",
    "import time\n",
    "\n",
    "def get_sol(X,y,g,Gamma):\n",
    "    '''\n",
    "    Returns the max kappa_in and max kappa_out solutions\n",
    "    Input parameters:\n",
    "    -----------------\n",
    "    X - an NxP input patterns array\n",
    "    y - a P vector of desired labels (+-1)\n",
    "    g - an N vector of the input affarent type: \n",
    "        +1 for an excitatory input and -1 for an inhibitory input.    \n",
    "    Gamma - Max norm of weight vector\n",
    "    \n",
    "    Returns:\n",
    "    w_in - max kappa_in solution\n",
    "    w_out - max kapa_out solution\n",
    "    '''\n",
    "    #find max kappa_out solution\n",
    "    w,theta,tau,sol,converged_to_solution = \\\n",
    "    sign_constrained_perceptron_max_kappa_out(X,y,g,Gamma)\n",
    "    #calculate 'physical' weights\n",
    "    w_out=(w/theta).flatten()\n",
    "    \n",
    "    #find max kappa_in solution\n",
    "    w,theta,tau,sol,converged_to_solution = \\\n",
    "        sign_constrained_perceptron_max_kappa_in(X,y,g,Gamma)\n",
    "    #calculate 'physical' weights\n",
    "    w_in=(w/theta).flatten()\n",
    "    \n",
    "    return w_in,w_out\n",
    "    \n",
    "def run_sim(nsim=1,n_rep=100):\n",
    "    '''\n",
    "    Runs nsim simulation on the IPyCluster\n",
    "    n_rep - number of times to present each pattern\n",
    "    \n",
    "    Uses global variables defined in 'Local Parameters'\n",
    "    '''\n",
    "    n_spikes_out=[]\n",
    "    n_spikes_in=[]\n",
    "    y_vec=[]\n",
    "    \n",
    "    #Generate patterns\n",
    "    X,y,P,g = gen_random_patterns(N,f_out,g_ex,alpha,Pex,Pinh(A_inh,k,dxbar))  \n",
    "    #save desired labels of patterns to list y_vec\n",
    "    y_vec.append(y)\n",
    "    #find solutions\n",
    "    w_in,w_out=get_sol(X,y,g,Gamma)\n",
    "    \n",
    "    #Send data to engines and waits to completion\n",
    "    dview.push({'X':X,'y':y,'w_in':w_in,'w_out':w_out},block=True)\n",
    "    \n",
    "    #Sets the weights of remote LIF neurons and waits for completion\n",
    "    dview.execute('set_weights()',block=True)\n",
    "     \n",
    "    for sim in range(nsim):\n",
    "        tt=time.time()\n",
    "        #send jobs to engiens\n",
    "        #testing the max kappa_out solution\n",
    "        amr_out=[lbview.map(activate_out,range(P),chunksize=500) for n in range(n_rep)]\n",
    "        #testing the max kappa_in solution\n",
    "        amr_in=[lbview.map(activate_in,range(P),chunksize=500) for n in range(n_rep)]\n",
    "        \n",
    "        #while engiens test solutions generate new solutions\n",
    "        if sim+1 < nsim:\n",
    "            #Generate patterns\n",
    "            X,y,P,g = gen_random_patterns(N,f_out,g_ex,alpha,Pex,Pinh(A_inh,k,dxbar))  \n",
    "            #save desired labels of patterns to lis y_vec\n",
    "            y_vec.append(y)\n",
    "            #find solutions\n",
    "            w_in,w_out=get_sol(X,y,g,Gamma)\n",
    "        \n",
    "        #gather results\n",
    "        #each result is an n_rep x P array of the number of output spikes \n",
    "        #for each pattern presentation\n",
    "        n_spikes_out.append(array([a.result() for a in amr_out]))\n",
    "        n_spikes_in.append(array([a.result() for a in amr_in]))\n",
    "        \n",
    "        #send new patterns to engines\n",
    "        if sim+1 < nsim:\n",
    "            dview.push({'X':X,'y':y,'w_in':w_in,'w_out':w_out},block=True)\n",
    "            dview.execute('set_weights()',block=True)\n",
    "        print(\"Sim {} complete in {} sec\".format(sim+1,time.time()-tt))\n",
    "    #return results\n",
    "    return n_spikes_out,n_spikes_in,y_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform no output noise condition simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spikes_out,n_spikes_in,y_vec=run_sim(10,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results to a dictionary\n",
    "res={'low_output_noise':{'n_spikes_in':n_spikes_in,\\\n",
    "                         'n_spikes_out':n_spikes_out,\\\n",
    "                         'y_vec':y_vec}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform high output noise condition simulation\n",
    "\n",
    "## Remote defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px \n",
    "#noise parameters for high output noise condition\n",
    "N_noise = 30000\n",
    "sigma_noise_w = 2./sqrt(N_noise)\n",
    "\n",
    "#New LIF Neurons for the high output noise cndition\n",
    "tempo_in = ST.SpikingTempotron(N+N_noise,1.,0.,LIFtheta)\n",
    "tempo_in.K = K\n",
    "\n",
    "\n",
    "tempo_out = ST.SpikingTempotron(N+N_noise,1.,0.,LIFtheta)\n",
    "tempo_out.K = K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spikes_out,n_spikes_in,y_vec=run_sim(40,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result to dict\n",
    "res.update({'high_output_noise':{'n_spikes_in':n_spikes_in,\\\n",
    "                                 'n_spikes_out':n_spikes_out,\\\n",
    "                                 'y_vec':y_vec}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save res dict to disk in your favorite way\n",
    "##...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shut down engiens if you wish\n",
    "c.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Figures From Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load res dict \n",
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_ax(ax):\n",
    "    ax.spines['top'].set_visible(0)\n",
    "    ax.tick_params(top=False,right=False,which='both')\n",
    "    ax.spines['right'].set_visible(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.style.use('classic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close()\n",
    "rcParams['font.size']=9\n",
    "title_pos=[-0.35,1.0]\n",
    "title_fs=10\n",
    "lbl_fs=8\n",
    "\n",
    "f=figure(figsize=[4.5,4.5])\n",
    "\n",
    "from matplotlib import gridspec\n",
    "\n",
    "gs=gridspec.GridSpec(10,10)\n",
    "\n",
    "#########################################################\n",
    "################## low output noise #####################\n",
    "#########################################################\n",
    "globals().update(res['low_output_noise'])\n",
    "\n",
    "arr_n_spikes_out=hstack(n_spikes_out[:])\n",
    "arr_n_spikes_in=hstack(n_spikes_in[:])\n",
    "\n",
    "#indexes for 'plus' and 'minus' patterns\n",
    "plus_ind = find(vstack(y_vec[:])==1)\n",
    "minus_ind = find(vstack(y_vec[:])==-1)\n",
    "#########################################################\n",
    "ax=f.add_subplot(gs[1:5,1:4])\n",
    "format_ax(ax)\n",
    "ax.set_title('(a)',fontsize=title_fs,position=title_pos)\n",
    "\n",
    "hp_out=hist(arr_n_spikes_out[:,plus_ind].flatten(),arange(60)-0.5,normed=True,\\\n",
    "           histtype='step',label=\"`plus' patterns\")\n",
    "hm_out=hist(arr_n_spikes_out[:,minus_ind].flatten(),arange(60)-0.5,normed=True,\\\n",
    "           histtype='step',label=\"`minus' patterns\",ec='r')\n",
    "\n",
    "xlabel('Spike Count',fontsize=lbl_fs)\n",
    "ylabel('Probability',fontsize=lbl_fs)\n",
    "legend(loc=(.9,-0.77),fontsize=6)\n",
    "#title(r'Max. $\\kappa_\\mathrm{out}$ solution')\n",
    "xlim(-1,30)\n",
    "xticks([0,10,20,30])\n",
    "ylim(0,0.5)\n",
    "yticks([0,0.2,0.4])\n",
    "####################################################################################33\n",
    "ax=f.add_subplot(gs[1:5,4:7])\n",
    "format_ax(ax)\n",
    "ax.set_title('(b)',fontsize=title_fs,position=title_pos)\n",
    "\n",
    "hp_in=hist(arr_n_spikes_in[:,plus_ind].flatten(),arange(60)-0.5,normed=True,\\\n",
    "           histtype='step',label=\"`plus' patterns\")\n",
    "hm_in=hist(arr_n_spikes_in[:,minus_ind].flatten(),arange(60)-0.5,normed=True,\\\n",
    "           histtype='step',label=\"`minus' patterns\",ec='r')\n",
    "\n",
    "xlabel('Spike Count',fontsize=lbl_fs)\n",
    "ylabel('Probability',fontsize=lbl_fs)\n",
    "#legend(loc='upper right',fontsize=9)\n",
    "#title(r'Max. $\\kappa_\\mathrm{in}$ solution')\n",
    "xlim(-1,16)\n",
    "xticks([0,5,10,15])\n",
    "ylim(0,0.5)\n",
    "yticks([0,0.2,0.4])\n",
    "#######################################################################################333\n",
    "ax=f.add_subplot(gs[1:5,7:])\n",
    "format_ax(ax)\n",
    "ax.set_title('(c)',fontsize=title_fs,position=title_pos)\n",
    "\n",
    "plot(1-cumsum(hp_out[0]),cumsum(hm_out[0]),lw=2,color='k',label=r'Max. $\\kappa_\\mathrm{out}$')\n",
    "plot(1-cumsum(hp_in[0]),cumsum(hm_in[0]),'--o',color='0.5',lw=2,label=r'Max. $\\kappa_\\mathrm{in}$',mec='none')\n",
    "ylim(0,1.05)\n",
    "yticks([0,0.5,1])\n",
    "xlim(0,1.05)\n",
    "xticks([0,0.5,1])\n",
    "\n",
    "xlabel(\"'plus' fraction\\ncorrect\",fontsize=lbl_fs)\n",
    "ylabel(\"'minus' fraction\\ncorrect\",fontsize=lbl_fs)\n",
    "#ax.set_aspect(1)\n",
    "legend(loc=(0.075,-0.77),fontsize=6,numpoints=1)\n",
    "#########################################################\n",
    "################## high output noise #####################\n",
    "#########################################################\n",
    "\n",
    "globals().update(res['high_output_noise'])\n",
    "\n",
    "arr_n_spikes_out=hstack(n_spikes_out[:])\n",
    "arr_n_spikes_in=hstack(n_spikes_in[:])\n",
    "\n",
    "plus_ind = find(vstack(y_vec[:])==1)\n",
    "minus_ind = find(vstack(y_vec[:])==-1)\n",
    "#########################################################################################\n",
    "ax=f.add_subplot(gs[6:,1:4])\n",
    "format_ax(ax)\n",
    "ax.set_title('(d)',fontsize=title_fs,position=title_pos)\n",
    "\n",
    "hp_out=hist(arr_n_spikes_out[:,plus_ind].flatten(),arange(60)-0.5,normed=True,\\\n",
    "           histtype='step',label=\"'plus' patterns\")\n",
    "hm_out=hist(arr_n_spikes_out[:,minus_ind].flatten(),arange(60)-0.5,normed=True,\\\n",
    "           histtype='step',label=\"'minus' patterns\",ec='r')\n",
    "\n",
    "xlabel('Spike Count',fontsize=lbl_fs)\n",
    "ylabel('Probability',fontsize=lbl_fs)\n",
    "#legend(loc='upper right',fontsize=9)\n",
    "#title(r'Max. $\\kappa_\\mathrm{out}$ solution')\n",
    "xlim(-1,30)\n",
    "xticks([0,10,20,30])\n",
    "ylim(0,0.5)\n",
    "yticks([0,0.2,0.4])\n",
    "###################################################################################333\n",
    "ax=f.add_subplot(gs[6:,4:7])\n",
    "format_ax(ax)\n",
    "ax.set_title('(e)',fontsize=title_fs,position=title_pos)\n",
    "\n",
    "\n",
    "hp_in=hist(arr_n_spikes_in[:,plus_ind].flatten(),arange(60)-0.5,normed=True,\\\n",
    "           histtype='step',label=\"`plus' patterns\")\n",
    "hm_in=hist(arr_n_spikes_in[:,minus_ind].flatten(),arange(60)-0.5,normed=True,\\\n",
    "           histtype='step',label=\"`minus' patterns\",ec='r')\n",
    "\n",
    "xlabel('Spike Count',fontsize=lbl_fs)\n",
    "ylabel('Probability',fontsize=lbl_fs)\n",
    "#legend(loc='upper right',fontsize=9)\n",
    "#title(r'Max. $\\kappa_\\mathrm{in}$ solution')\n",
    "xlim(-1,16)\n",
    "xticks([0,5,10,15])\n",
    "ylim(0,0.5)\n",
    "yticks([0,0.2,0.4])\n",
    "\n",
    "######################################################################################33\n",
    "ax=f.add_subplot(gs[6:,7:])\n",
    "format_ax(ax)\n",
    "ax.set_title('(f)',fontsize=title_fs,position=title_pos)\n",
    "\n",
    "plot(1-cumsum(hp_out[0]),cumsum(hm_out[0]),lw=2,color='k')\n",
    "plot(1-cumsum(hp_in[0]),cumsum(hm_in[0]),'--o',color='0.5',lw=2,mec='none')\n",
    "ylim(0,1.05)\n",
    "yticks([0,0.5,1])\n",
    "xlim(0,1.05)\n",
    "xticks([0,0.5,1])\n",
    "xlabel(\"'plus' fraction\\ncorrect\",fontsize=lbl_fs)\n",
    "ylabel(\"'minus' fraction\\ncorrect\",fontsize=lbl_fs)\n",
    "#ax.set_aspect(1)\n",
    "\n",
    "###########################################################################\n",
    "f.text(0.00,0.85,\"No Output Noise\",fontsize=10,rotation='vertical')\n",
    "f.text(0.00,0.375,\"High Output Noise\",fontsize=10,rotation='vertical')\n",
    "f.text(0.1,0.92,\"Balanced\\n\"+r\"max. $\\kappa_\\mathrm{out}$ Solution\",\\\n",
    "       fontsize=10,multialignment='center')\n",
    "f.text(0.425,0.92,\"Unbalanced\\n\"+r\"max. $\\kappa_\\mathrm{in}$ Solution\",\\\n",
    "       fontsize=10,multialignment='center')\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure S4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals().update(res['low_output_noise'])\n",
    "\n",
    "arr_n_spikes_out=hstack(n_spikes_out[:])\n",
    "arr_n_spikes_in=hstack(n_spikes_in[:])\n",
    "\n",
    "plus_ind = find(vstack(y_vec[:])==1)\n",
    "minus_ind = find(vstack(y_vec[:])==-1)\n",
    "\n",
    "close()\n",
    "mpl.style.use('classic')\n",
    "rcParams['font.size']=8\n",
    "\n",
    "f=figure(1,figsize=[3.42,2.1])\n",
    "title_pos=[-0.35,1.]\n",
    "title_fs=9\n",
    "latex_fs=12\n",
    "ax=subplot(121)\n",
    "format_ax(ax)\n",
    "\n",
    "r=arange(-0.25,60,0.5)\n",
    "\n",
    "hist(mean(arr_n_spikes_out[:,plus_ind],0),r,normed=True,histtype='step',label=\"'plus' pat.\")\n",
    "hist(mean(arr_n_spikes_out[:,minus_ind],0),r,normed=True,histtype='step',label=\"'minus' pat.\",ec='r')\n",
    "xlabel('Mean Spike Count')\n",
    "ylabel('Probability Density')\n",
    "legend(loc='upper right',fontsize=6)\n",
    "title('Balanced\\n'+r'max. $\\kappa_\\mathrm{out}$ solution',fontsize=title_fs)\n",
    "xlim(-1,20)\n",
    "ylim(0,.7)\n",
    "yticks([0,0.3,0.6])\n",
    "#ylim(0,0.55)\n",
    "\n",
    "ax=subplot(122)\n",
    "format_ax(ax)\n",
    "\n",
    "hist(mean(arr_n_spikes_in[:,plus_ind],0),r,normed=True,histtype='step',label=\"'plus' pat.\",lw=1)\n",
    "hist(mean(arr_n_spikes_in[:,minus_ind],0),r,normed=True,histtype='step',label=\"'minus' pat.\",ec='r',lw=1)\n",
    "xlabel('Mean Spike Count')\n",
    "ylabel('Probabilty Density')\n",
    "legend(loc='upper right',fontsize=6)\n",
    "title('Unbalanced\\n'+r'max. $\\kappa_\\mathrm{in}$ solution',fontsize=title_fs)\n",
    "xlim(-1,10)\n",
    "ylim(0,2.2)\n",
    "yticks([0,1,2.])\n",
    "tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
